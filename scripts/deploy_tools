#!/usr/bin/env python
# encoding: UTF-8
"""Deploy current versions of all tools within KS_TOOLS.

Pulls the master branch from each deployed_repo's origin, cleans up any orphaned *.pyc
files, and compiles any new *.py files.

"""

from subprocess import call, check_call, CalledProcessError
import optparse
import os
import py_compile
import re
import sys
import time

from sitetools.repos import git_call, git_output, git_remotes, git_rev_parse, git_distance
from sitetools.platform import basic_platform_spec, extended_platform_spec
from sitetools.utils import colour


def error(message):
    print '   ', colour('ERROR:', fg='red', reset=True), str(message)

def warning(message):
    print '   ', colour('WARNING:', fg='yellow', reset=True), str(message)





def compile_bytecode(fullname, debug=False, force=False, quiet=False):
    """Compile bytecode for given file.
    
    Generally lifted from compile all since compileall.compile_file was not
    availible until Python 2.7, but extended to be more forgiving of our NFS'
    inability to keep time.
    
    """
    
    cfile = fullname + (__debug__ and 'c' or 'o')
    ftime = os.stat(fullname).st_mtime
    try:
        ctime = os.stat(cfile).st_mtime
    except os.error:
        ctime = 0
    
    # Pull future times back to reality.
    if ftime > time.time():
        print 'Future mtime on', fullname
        os.utime(fullname, None)
    
    if (ctime > ftime) and not force:
        return
    
    if not quiet:
        print 'Compiling', fullname, '...'
    
    try:
        py_compile.compile(fullname, cfile, None, True)
    
    except KeyboardInterrupt:
        raise KeyboardInterrupt
    
    except py_compile.PyCompileError, err:
        if quiet:
            print 'Compiling', fullname, '...'
        print err.msg
    
    except IOError, e:
        print colour("ERROR:", bg='red', reset=True), e
    

optparser = optparse.OptionParser()

optparser.add_option('-a', '--all', action='store_true', help='operate on all tools, not just those you have locally')
optparser.add_option('-n', '--dry-run', action='store_true', help='don\'t do anything, just report')

optparser.add_option('-f', '--force', action='store_true', help='re-build even if there are no changes')

optparser.add_option('--nomake',  action='store_true', help='skip running `make`')
optparser.add_option('--nobuild', action='store_true', help='skip running `python setup.py build`')
optparser.add_option('--nopyc',   action='store_true', help='skip byte-compiling Python source files')

optparser.add_option('--clean', action='store_true', help='clean out files not managed by git')
optparser.add_option('--reset', action='store_true', help='`git reset --hard` instead of fast-forwarding')


opts, args = optparser.parse_args()


# Lookup location of tools.
ks_tools = os.environ['KS_TOOLS']


# Allow the user to specify which tools to deploy.
if args:
    if args == ['.']:
        tool_names = [os.path.basename(os.getcwd())]
    else:
        tool_names = list(args)
elif opts.all:
    tool_names = sorted(os.listdir(ks_tools))
else:
    tool_names = set()
    for dev_path in ('~/key_tools', '~/dev', '~/key_local_tool_development'):
        dev_path = os.path.expanduser(dev_path)
        if os.path.exists(os.path.join(dev_path)):
            for name in os.listdir(dev_path):
                if os.path.exists(os.path.join(dev_path, name, '.git')):
                    tool_names.add(name)
    tool_names = sorted(tool_names)


for tool_name in tool_names:
    
    if tool_name.startswith('.'):
        continue
    
    print '==>', colour(tool_name, fg='blue', reset=True)
    
    tool_path = os.path.join(ks_tools, tool_name)
    if not os.path.exists(tool_path):
        warning('Tool does not exist in $KS_TOOLS.')
        continue
    
    deployed_repo = os.path.join(tool_path, '.git')
    if not os.path.exists(deployed_repo):
        error('Deployed tool is not a git deployed_repo.')
        continue
    
    # Get current commit to see if we need to do the cleanups later.
    deployed_head = git_rev_parse(deployed_repo, 'HEAD')
    
    # Get current master of the origin.
    remotes = git_remotes(deployed_repo)
    if 'origin' not in remotes:
        error('Could not find origin')
        continue
    global_repo = remotes['origin']
    if (not os.path.exists(global_repo) and
        not global_repo.startswith('git@git.westernx:westernx/') and
        not global_repo.startswith('git@github.com:')
    ):
        error('Found origin does not appear valid: %r' % global_repo)
        continue

    # Get the new commits.
    git_call(deployed_repo, 'fetch', 'origin')
    global_master = git_rev_parse(deployed_repo, 'origin/master')
    
    # Take a peek at our development tools.
    for dev_path in ('~/key_tools', '~/dev', '~/key_local_tool_development'):
        dev_repo = os.path.join(os.path.expanduser(dev_path), tool_name, '.git')
        if not os.path.exists(dev_repo):
            continue
        
        dev_head = git_rev_parse(dev_repo, 'HEAD')
        
        # We have the deployed head, so whatevs.
        if dev_head == deployed_head:
            break

        dev_origin_master = git_rev_parse(dev_repo, 'origin/master')
        
        # Are we ahead or behind?
        # TODO: this can fail if they have forked and the divergent heads are
        #       not both in the global repo (e.g. someone has pushed commits
        #       only to the deployed repo).
        local_left, local_right = git_distance(dev_repo, dev_head, dev_origin_master)
        remote_left, remote_right = git_distance(deployed_repo, dev_origin_master, deployed_head)
        ahead = local_left + remote_left
        behind = local_right + remote_right
        
        if ahead and behind:
            warning('You and the tool have forked; please rebase.')
            warning('There are %d local commit%s, and %d remote commit%s.' % (
                ahead, 's' if ahead > 1 else '', behind, 's' if behind > 1 else ''
            ))
        elif ahead:
            print '   ', colour('You are ahead by %d commit%s.' % (ahead, 's' if ahead > 1 else ''), fg='green', reset=True)
        elif behind:
            warning('You are behind by %d commit%s.' % (behind, 's' if behind > 1 else ''))
        
    # Don't bother doing the merge or cleanups if we wouldn't move anyways.
    if not opts.force and global_master == deployed_head:
        continue
    
    if opts.dry_run:
        print '    Deploy skipped due to dry run.'
        continue
    
    # Do the reset or merge.
    if opts.reset:
        try:
            git_call(deployed_repo, 'reset', '--hard', 'origin/master')
        except CalledProcessError:
            error('Git error during reset.')
            continue
    else:
        try:
            git_call(deployed_repo, 'merge', '--ff-only', 'origin/master')
        except CalledProcessError:
            error('Git error during fast-forward (merge); --reset to force.')
            continue
    
    # Clean up files that are untracked by git.
    if opts.clean:
        git_call(deployed_repo, 'clean', '-dXf')
    
    # Add rpaths to libs
    if 'DEPLOY_TOOLS_RPATHS' in os.environ:
        rpaths =  '  '.join([ '-Wl,-rpath,' + p for p in os.environ['DEPLOY_TOOLS_RPATHS'].split(":")])
        if rpaths:
            if 'LDFLAGS' not in os.environ:
                 os.environ['LDFLAGS'] = ''
            os.environ['LDFLAGS'] += rpaths

    # Run a top-level Makefile if it exists.
    if not opts.nomake and os.path.exists(os.path.join(tool_path, 'Makefile')):
        check_call(['make', '-j4'], cwd=tool_path)

    # Build via setuptools.
    setup_path = os.path.join(tool_path, 'setup.py')
    if not opts.nobuild and os.path.exists(setup_path):

        # We try to get compiled extensions to build into a directory that is
        # more specific than distutils tends to do. Just in case it refuses to
        # comply, we still look for the default compiled path.

        temp_path = os.path.join(tool_path, 'build', 'temp.' + extended_platform_spec)
        purelib_path = os.path.join(tool_path, 'build', 'lib')
        platlib_default_path = os.path.join(tool_path, 'build', 'lib.' + basic_platform_spec)
        platlib_extended_path = os.path.join(tool_path, 'build', 'lib.' + extended_platform_spec)

        if call(['python', 'setup.py',
            'build',
                '--build-temp', temp_path,
                '--build-purelib', purelib_path,
                '--build-platlib', platlib_extended_path,
                '--build-scripts', os.path.join(tool_path, 'build', 'scripts-build'),
            'install_scripts',
                '--install-dir', os.path.join(tool_path, 'build', 'scripts'),
        ], cwd=tool_path):
            error('Could not build Python package')
            continue

        is_extended = os.path.exists(platlib_extended_path)
        is_pure = not is_extended and os.path.exists(purelib_path)

        # Install egg-info (for entry_points, mostly).
        # Need to inject setuptools for this.
        if call(['python', '-c', 'import setuptools; __file__="%s"; execfile(__file__)' % (setup_path, ),
            'install_egg_info', '-d', purelib_path if is_pure else (platlib_extended_path if is_extended else platlib_default_path),
        ], cwd=tool_path):
            error('Could not build Python egg_info')
            continue

        print 'Writing %s.pth' % tool_path
        with open(tool_path + '.pth', 'w') as fh:
            fh.write('# Autogenerated by deploy_tools\n')
            if is_extended:
                fh.write('%s/build/lib.{extended_platform_spec}\n' % os.path.basename(tool_path))
            elif is_pure:
                fh.write('%s/build/lib\n' % os.path.basename(tool_path))
            else:
                fh.write('%s/build/lib.{basic_platform_spec}\n' % os.path.basename(tool_path))
    
    # Find all Python source code and compile it to bytecode while removing
    # orphaned bytecode.
    if not opts.nopyc:
        print 'Looking for Python sources...'
        for dir_path, dir_names, file_names in os.walk(tool_path):
            visited = set()
            for file_name in file_names:
            
                # We only care about Python source code (for now).
                if file_name.startswith('.'):
                    continue
                if os.path.splitext(file_name)[1] not in ('.py', '.pyc'):
                    continue
                
                # Normalize to the source file.
                file_name = file_name.rstrip('c')
                
                # Only deal with one of the source or compiled.
                if file_name in visited:
                    continue
                visited.add(file_name)
                
                # Compile bytecode if the file exists, and remove bytecode if
                # the file does not.
                file_path = os.path.join(dir_path, file_name)
                if os.path.exists(file_path):
                    compile_bytecode(file_path)
                elif os.path.exists(file_path + 'c'):
                    print 'Removing', file_path + 'c'
                    os.unlink(file_path + 'c')
    
